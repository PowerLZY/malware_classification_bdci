#!/usr/bin/env python
# -*- encoding: utf-8 -*-
'''
@File    :   feature_engineering.py    
@Contact :   3289218653@qq.com
@License :   (C)Copyright 2021-2022 PowerLZY

@Modify Time      @Author           @Version    @Desciption
------------      -------           --------    -----------
2021-10-04 17:17   PowerLZY&yuan_mes  1.0         None
'''
import sys
import os

from code.model import *
from code.features import *
from code.utils import *
from sklearn.feature_extraction.text import TfidfVectorizer

if __name__ == '__main__':
    # TODO : sys.argv -data_type = "trian or test" -data_path '../data/raw_data' -inter_path '../data/user_data'
    data_path = '../data/raw_data'
    data_type = "train"
    inter_path = '../data/user_data'

    pe_path = f"{data_path}/{data_type}/pe"
    asm_path = f"{data_path}/{data_type}/asm"

    test_pe_path = f"{data_path}/test/pe"
    test_asm_path = f"{data_path}/test/asm"

    if data_type == 'train':
        fix_file_index(data_path, inter_path)

        # TODO: define a function(obj, sample_path, inter_path, vectorizer_gram...) for words&ins
        # ------------------------ words ------------------------
        feature_tfidf_csv(StringExtractor(), pe_path, inter_path)
        feature_tfidf_csv(StringExtractor(), test_pe_path, inter_path)
        train_words_ = pd.read_csv(f"{inter_path}/train_words_tfidf.csv")
        test_words_ = pd.read_csv(f"{inter_path}/test_words_tfidf.csv")
        all_words_ = train_words_.append(test_words_)

        vectorizer_w = TfidfVectorizer()
        vectorizer_w.fit(all_words_.word_feature.tolist())
        joblib.dump(vectorizer_w, open(f"{inter_path}/models/TFIDF_model_words.pth", "wb"))
        # ------------------------ ins ------------------------
        feature_tfidf_csv(OpcodeInfo(), asm_path, inter_path)
        feature_tfidf_csv(OpcodeInfo(), test_asm_path, inter_path)
        train_ins_ = pd.read_csv(f"{inter_path}/train_ins_tfidf.csv")
        test_ins_ = pd.read_csv(f"{inter_path}/test_ins_tfidf.csv")
        all_ins_ = train_ins_.append(test_ins_)

        vectorizer_i = TfidfVectorizer(stop_words=[';'], ngram_range=(1, 3))
        vectorizer_i.fit(all_ins_.ins_list.tolist())
        joblib.dump(vectorizer_i, open(f"{inter_path}/models/TFIDF_model_ins.pth", "wb"))

        # ------------------------ semantic ------------------------
        feature_asm2txt(asm_path, inter_path)
        feature_asm2txt(test_asm_path, inter_path)

    pe_objs = [ByteHistogram(), ByteEntropyHistogram(), StringExtractor()]
    for obj in pe_objs:
        feature_engineering(obj, pe_path, inter_path)

    asm_objs = [SectionInfo(), ImportsInfo(), ExportsInfo()]
    for obj in asm_objs:
        feature_engineering(obj, asm_path, inter_path)

    # TODO: define a function(obj, inter_path, vectorizer_gram, data_type...) for words&ins
    # ------------------------ words ------------------------
    vectorizer_w = joblib.load(open(f"{inter_path}/models/TFIDF_model_words.pth", "rb"))
    vectorizer_w.max_features = 300
    words_ = pd.read_csv(f"{inter_path}/{data_type}_words_tfidf.csv")
    words = vectorizer_w.transform(words_.word_feature)
    np.save(f"{inter_path}/{data_type}_words_{vectorizer_w.max_features}.npy", words.toarray())
    # ------------------------ ins ------------------------
    vectorizer_i = joblib.load(open(f"{inter_path}/models/TFIDF_model_ins.pth", "rb"))
    vectorizer_i.max_features = 1000
    ins_ = pd.read_csv(f"{inter_path}/{data_type}_ins_tfidf.csv")
    ins = vectorizer_i.transform(ins_.ins_list)
    np.save(f"{inter_path}/{data_type}_ins_{vectorizer_i.max_features}.npy", ins.toarray())
    # ------------------------ semantic ------------------------
    feature_asm2vec(data_type, inter_path)  # data_type

    # TODO 特征融合 'ember_section_ins_words', 'ember_section_ins_semantic'
