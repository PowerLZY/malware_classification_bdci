#!/usr/bin/env python
# -*- encoding: utf-8 -*-
'''
@File    :   feature_engineering.py    
@Contact :   3289218653@qq.com
@License :   (C)Copyright 2021-2022 PowerLZY

@Modify Time      @Author           @Version    @Desciption
------------      -------           --------    -----------
2021-10-04 17:17   PowerLZY&yuan_mes  1.0         None
'''
import sys
import os

from code.model import *
from code.features import *
from code.utils import *
from sklearn.feature_extraction.text import TfidfVectorizer


if __name__ == '__main__':
    # TODO : sys.argv -data_type = trian or test
    data_path = '../data/raw_data'
    inter_path = '../data/user_data'

    train_pe_path = f"{data_path}/train/pe"
    train_asm_path = f"{data_path}/train/asm"
    test_pe_path = f"{data_path}/test/pe"
    test_asm_path = f"{data_path}/test/asm"

    fix_file_index(data_path, inter_path)

    # Feature engineering for features only generated by pe file in byte-format
    pe_objs = [ByteHistogram(), ByteEntropyHistogram(), StringExtractor()]
    for obj in pe_objs:
        feature_engineering(obj, train_pe_path, inter_path)

    # Feature engineering for features only generated by asm file in string-format
    asm_objs = [SectionInfo(), ImportsInfo(), ExportsInfo()]
    for obj in asm_objs:
        feature_engineering(obj, train_asm_path, inter_path)

    # Feature engineering for features transformed by tf-idf
    feature_tfidf(StringExtractor(), train_pe_path, inter_path)
    feature_tfidf(StringExtractor(), test_pe_path, inter_path)
    feature_tfidf(OpcodeInfo(), train_asm_path, inter_path)
    feature_tfidf(OpcodeInfo(), test_asm_path, inter_path)

    # ------------------------ words ------------------------
    # TODO: define a function
    train_words_ = pd.read_csv(f"{inter_path}/train_words_tfidf.csv")
    test_words_ = pd.read_csv(f"{inter_path}/test_words_tfidf.csv")
    all_words_ = train_words_.append(test_words_)

    vectorizer_w = TfidfVectorizer()
    vectorizer_w.fit(all_words_.word_feature.tolist())
    joblib.dump(vectorizer_w, open(f"{inter_path}/models/TFIDF_model_words.pth", "wb"))

    vectorizer_w.max_features = 300
    train_words = vectorizer_w.transform(train_words_.word_feature)
    np.save(f"{inter_path}/train_words_{vectorizer_w.max_features}.npy", train_words.toarray())
    # ------------------------ ins ------------------------
    # TODO: define a function
    train_ins_ = pd.read_csv(f"{inter_path}/train_ins_tfidf.csv")
    test_ins_ = pd.read_csv(f"{inter_path}/test_ins_tfidf.csv")
    all_ins_ = train_ins_.append(test_ins_)

    vectorizer_i = TfidfVectorizer(stop_words = [';'], ngram_range =(1,3))
    vectorizer_i.fit(all_ins_.ins_list.tolist())
    joblib.dump(vectorizer_i, open(f"{inter_path}/models/TFIDF_model_ins.pth", "wb"))

    vectorizer_i.max_features = 1000
    train_ins = vectorizer_i.transform(train_ins_.ins_list)
    np.save(f"{inter_path}/train_ins_{vectorizer_i.max_features}.npy", train_ins.toarray())
    # ------------------------ semantic ------------------------
    #train_all[np.isnan(train_all)] = 0
    feature_asm2vec("train", inter_path) # data_type
