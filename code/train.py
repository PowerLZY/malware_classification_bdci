import warnings
import pandas as pd
from model import *
from feature import *
from tqdm import tqdm
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel

warnings.filterwarnings('ignore')


def fix_file_index(data_path, inter_path):
    """ Fix the index of training set input and test set result output. """

    train_lab_path = f"{data_path}/train/train_label.csv"
    train_label = pd.read_csv(train_lab_path)
    train_filename = train_label['filename'].tolist()

    # How to generate current index of test_filename
    # TO BE ADDED...
    # test_filename =
    # test_filename.to_csv(f"{inter_path}/test_filename.txt", header=False, index=False)

    # Get rid of training samples labeled 7, 8, 9 but not in the test set
    other_filename = \
    train_label[train_label['family'].isin([7, 8, 9]) & (~train_label['filename'].isin(test_filename))][
        'filename'].tolist()
    train_filename = [i for i in train_filename if i not in other_filename]
    train_label = train_label[train_label['filename'].isin(train_filename)]
    train_filename = train_label['filename']
    train_y = np.array(train_label['family'])
    train_filename.to_csv(f"{inter_path}/train_filename.txt", header=False, index=False)
    np.save(f"{inter_path}/train_y.npy", train_y)


def train_model(inter_path, label):
    """ Train a model for specific labeled feature generated before. """

    xgb_model = XGBClassifier(
        objective='multi:softprob',
        num_class=10,
        max_depth=6,
        n_estimators=90,
        learning_rate=0.1,
        eval_metric='mlogloss',
        use_label_encoder=False
    )
    train_fea_path = f"{inter_path}/train_{label}.npy"
    train_lab_path = f"{inter_path}/train_y.npy"
    train_X = np.load(train_fea_path)
    train_y = np.load(train_lab_path)
    clf = Model(xgb_model, train_X, train_y, label, inter_path)
    clf.Fit()


data_path = '../data/raw_data'
inter_path = '../data/user_data'
fix_file_index(data_path, inter_path)

# Feature engineering for features only generated by pe file in byte-format
train_pe_path = f"{data_path}/train/pe"
pe_objs = [ByteHistogram(), ByteEntropyHistogram(), StringExtractor()]
for obj in pe_objs:
    feature_engineering(obj, train_pe_path, inter_path)

# Feature engineering for features only generated by asm file in string-format
train_asm_path = f"{data_path}/train/asm"
asm_objs = [SectionInfo(), ImportsInfo(), ExportsInfo()]
for obj in asm_objs:
    feature_engineering(obj, train_asm_path, inter_path)

# Example for following 2 process: Ember features
# Maybe define a function...

# Feature fusion
# TO BE MODIFIED...
fused_label = 'ember'
features = ['histogram', 'byteentropy', 'strings']
data_type = ['train', 'test']
arr = []
for f in features:
    arr.append(np.load(f"{inter_path}/train_{f}.npy"))
np.save(f"{inter_path}/train_{fused_label}.npy", np.hstack(arr).astype(np.float32))

# Feature selection
# TO BE MODIFIED...
train_fea_path = f"{inter_path}/train_{fused_label}.npy"
train_lab_path = f"{inter_path}/train_y.npy"
train_X = np.load(train_fea_path)
train_y = np.load(train_lab_path)

selector = SelectFromModel(RandomForestClassifier(), threshold="0.2*mean")
train_X_r = selector.fit_transform(train_X, train_y)
selector_path = f"{inter_path}/feature_selector.pkl"
joblib.dump(selector, selector_path)
np.save(train_fea_path, train_X_r)


# Model training
train_model(inter_path, fused_label)
