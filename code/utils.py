#!/usr/bin/env python
# -*- encoding: utf-8 -*-
"""
@File    :   utils.py
@Contact :   3289218653@qq.com
@License :   (C)Copyright 2021-2022 PowerLZY

@Modify Time      @Author           @Version    @Desciption
------------      -------           --------    -----------
2021-10-04 17:22   PowerLZY&yuan_mes  1.0       归档工具函数
"""
import os
import numpy as np
import pandas as pd

from sklearn.metrics import log_loss


def file_list(path):
    """返回 filename 列表"""
    list = []
    for parent, dirnames, filenames in os.walk(path):
        for filename in filenames:
            list.append(filename)
    return list


def fix_file_index(data_path, inter_path):
    """ Fix the index of training set input and test set result output. """
    train_lab_path = f"{data_path}/train/train_label.csv"
    train_label = pd.read_csv(train_lab_path)
    train_filename = train_label['filename'].tolist()

    # How to generate current index of test_filename
    # TODO: BE MODIFIED Save
    test_filename = file_list(data_path + '/train/pe/')
    pd.DataFrame({'filename': test_filename}).to_csv(f"{inter_path}/test_filename.txt", header=False, index=False)

    # Get rid of training samples labeled 7, 8, 9 but not in the test set
    # TODO: BE MODIFIED
    other_filename = train_label[train_label['family'].isin([7, 8, 9]) \
                                 & (~train_label['filename'].isin(test_filename))]['filename'].tolist()
    train_filename = [i for i in train_filename if i not in other_filename]
    train_label = train_label[train_label['filename'].isin(train_filename)]
    train_filename = train_label['filename']
    train_y = np.array(train_label['family'])
    train_filename.to_csv(f"{inter_path}/train_filename.txt", header=False, index=False)
    np.save(f"{inter_path}/train_y.npy", train_y)


def vote_results(vote_list):
    """ 软投票结果集成 """
    result_ensamle = np.zeros([5024, 10], dtype=float)
    pred_list = []
    final = np.zeros([5024, 10], dtype=float)

    for res in vote_list:
        result_ensamle += res
    for sample in result_ensamle:
        pred_list.append(np.argmax(sample, axis=0))  # 求最大索引

    for i in range(final.shape[0]):
        final[i] = np.zeros([1, 10], dtype=float)
        vote = pred_list[i]
        for res in vote_list:
            if res[i][vote] > final[i][vote]:
                final[i] = res[i]

    return final


def vote_weight_results(labels_loss, vote_list):
    """
    软投票结果集成

    labels_loss:每个结果类权重矩阵 numpy
    vote_list:结果列表 （nshape, class_num）
    """

    result_ensamle = np.zeros([5024, 10], dtype=float)
    pred_list = []
    final = np.zeros([5024, 10], dtype=float)
    k = 0
    for res in vote_list:
        result_ensamle += res * labels_loss[:, k]
        k += 1
    for sample in result_ensamle:
        pred_list.append(np.argmax(sample, axis=0))  # 求最大索引

    for i in range(final.shape[0]):
        final[i] = np.zeros([1, 10], dtype=float)
        vote = pred_list[i]
        for res in vote_list:
            if res[i][vote] > final[i][vote]:
                final[i] = res[i]

    return final


def get_class_logloss(x):
    """计算每个类别的logloss"""
    class_pred = np.array(x.iloc[:, :-1])
    class_result = np.array(x['family'])
    class_loss = log_loss(class_result, class_pred, labels=[_ for _ in range(10)])
    return class_loss


def load_data(feature_list, inter_path):
    """获取train_data_dict, train_labels"""

    train_data_dict = {}
    for feature in feature_list:
        train_data_dict[feature] = f"{inter_path}/train_{feature}.npy"

    return train_data_dict